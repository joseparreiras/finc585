\citep{stambaugh1999predictive}. You will examine the bias in the slope coefficient in the regression of returns on past dividend yields, when the dividend yield process is highly persistent. Let \(y_t\) denote the return and \(x_t\) the dividend-price ratio (dividend yield) at date \(t\). Consider the following regression equations,

\begin{align*}
    y_t &= \alpha + \beta x_{t-1} + u_t \\
    x_t &= \theta + \rho x_{t-1} + v_t
\end{align*}

for \(t = 1, \dots, T\) and where,
\[
    \begin{bmatrix} u_t \\ v_t \end{bmatrix} \sim N(\mathbf 0_2, \Sigma)
\]

We can write the above equations in matrix form as follows,
\begin{align*}
    \mathbf{y} & = \alpha + \beta\mathbf{x} + \mathbf{u} \\ 
    \mathbf{x}^{+} & = \theta + \rho\mathbf{x} + \mathbf{v}
\end{align*}
where,
\begin{align*}
    \mathbf y & = \begin{bmatrix} y_1 & \cdots & y_T \end{bmatrix}^\prime \\
    \mathbf x & = \begin{bmatrix} x_0 & \cdots & x_{T-1} \end{bmatrix}^\prime \\
    \mathbf x^{+}  & = \begin{bmatrix} x_1 & \cdots & x_T \end{bmatrix}^\prime \\
    \mathbf u & = \begin{bmatrix} u_1 & \cdots & u_T \end{bmatrix}^\prime \\
    \mathbf v & = \begin{bmatrix} v_1 & \cdots & v_T \end{bmatrix}^\prime \\
\end{align*}

\begin{enumerate}[label = (\alph*)]
    \item  Show that 
    \[
        \widehat\beta = \beta + \begin{bmatrix}
            \mathbf{0} & \mathbf{1} 
        \end{bmatrix}(\mathbf{X}^\prime \mathbf{X})^{-1}\mathbf{X}^\prime \mathbf{u}
    \]
    where \(\mathbf{X} = \begin{bmatrix} \mathbf{1}_T & \mathbf x \end{bmatrix}\)
    \item Show that \(\mathbf{u}\) can be decomposed as \(\mathbf{u} = \frac{\sigma_{uv}}{\sigma_v^2}\mathbf v + \mathbf e\) where \(e\) is uncorrelated with \(v\), and,
    \[
        \widehat \beta = \beta + \frac{\sigma_{uv}}{\sigma_v^2}\begin{bmatrix}
            \mathbf{0} & \mathbf{1}
        \end{bmatrix}\left(\mathbf{X}^\prime \mathbf{X}\right)^{-1}\mathbf{X}^\prime \mathbf{v} + \begin{bmatrix}
            \mathbf{0} & \mathbf{1}
        \end{bmatrix}\left(\mathbf{X}^\prime \mathbf{X}\right)^{-1}\mathbf{X}^\prime \mathbf{e}
    \]
    \item Show that,
    \[
        \widehat \rho = \rho + \begin{bmatrix}
            \mathbf{0} & \mathbf{1}
        \end{bmatrix}\left(\mathbf{X} \mathbf{X}\right)^{-1}\mathbf{X} \mathbf{v}
    \]
    \item Show that
    \[
        \E{\widehat\beta-\beta} = \frac{\sigma_{uv}}{\sigma_v^2} \E{\widehat\rho - \rho}
    \]
    and, using the expression \(\E{\widehat\rho-\rho}\approx -\frac{1+3p}{T}\), for the finite sample bias of the estimated AR(1) coefficient from \citet{kendall1954note}, discuss the potential magnitude of the bias in \(\widehat\beta\) above, when \(T\) is 50 years, \(\rho = 0.94\) and \(\frac{\sigma_{uv}}{\sigma_v^2} = -1\).
    \item Try to interpret the implications of your results for predictive regressions more generally. The issues highlighted here have generated a large literature!
    \item Design a small Monte Carlo study to explore the size of bias in finite samples by experimenting with different values for sample size, \(T\), the degree of persistence in the regressor, \(\rho\), and the (normalized) covariance between the innovations, \(\sigma_{uv}\) (or \(\sigma_{uv}/\sigma_v^2\)). Please report some relevant findings.
\end{enumerate}